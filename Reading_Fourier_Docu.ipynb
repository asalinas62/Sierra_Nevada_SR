{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V:2022/04/01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pseudo code is shown in **bold** in the cell before each piece of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program `Reading_Fourier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of this program consist of the 1-hour data files for a month recorded for each sensor of the station.\n",
    "\n",
    "**This program has the following pseudo code:**\n",
    "\n",
    "1. **Reading each of the 1-hour data files.**\n",
    "2. **Splitting each 1-hour data file into 10-min data intervals.**\n",
    "3. **Dividing each 10-min interval into 10 s windows with a 5 s offset. Detecting of saturations in each window of 10 s and performing the Fast Fourier Transform (FFT) using the Welch method.**\n",
    "4. **Calibrating and averaging of the power spectrum for each 10 s interval over the 10-min interval. Output of the amplitude spectrum taking the square root of the averaged power spectrum.**\n",
    "\n",
    "As a final result, the amplitude spectrum is obtained for each 10-min interval of the month of measurements that has been processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inputs: Sierra Nevada ELF station data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python packages used in the program.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy package is used and imported with the alias `np`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Year and month to study.\n",
    "Input and output paths.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS/OUTPUTS PATH\n",
    "year='2015'\n",
    "month='1503'\n",
    "\n",
    "pathin='S_N_Data/'      # Input path \n",
    "pin=pathin+year+'/'+month+'/'\n",
    "     \n",
    "pathout='S_N_FD/'       # Output path\n",
    "pou=pathout+year+'/'+month+'/'    # Must have been created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected at the Sierra Nevada ELF station are grouped by years and months: `pathin + '/2015/1503'`, where 2015 and 1503 correspond to the year 2015 and the month of March. The figures for the year are repeated in order to avoid writing errors in the processing.\n",
    "The station data are in the directory 'S_N_Data' (indicated by the variable `pathin`) and the outputs of the processing carried out are located in 'S_N_FD' (indicated by the variable` pathout`).\n",
    "\n",
    "The data files for each month and each sensor are of two types: 1-hour data files and 1-hour time information files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, there are two files: ` ficheros0` and `ficheros1`, for the sensors NS and EW, respectively, that contain the list of the filenames.\n",
    "The name of each file is, for example, `smplGRTU1_sensor_0_1604301629`, where` smplGRTU1_sensor_` is common to all files; 0 is for sensor NS (1 corresponds to the sensor EW); there are pairs of numbers for the year, 16, month, 04, day, 30, hour, 16, and starting minute, 29. The information file has the same name but ends in `_info.txt`. There are some months that are not complete due to problems arisen at the station or due to maintenance work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of the ELF station characteristic parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmues=256       # Hz sampling freq\n",
    "facdat=10.0/2**15   # Sampling factor\n",
    "nhora=fmues*3600  # 921600   # Data per hour\n",
    "limsup=9.990        # Saturation superior bound\n",
    "liminf=-9.990        # Saturation lower bound\n",
    "(f1,f2)=(6,25)   # Calibrated band limits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the parameters of the measurement system: the sampling frequency `fmues`, the sampling factor (corresponds to the maximum voltage value, 10 V, divided by the factor corresponding to 15-bit, 16-bit sampling system minus 1 for the sign), `facdat`; the number of samples in an hour, `nhora`; the upper and lower saturation limits of the measurement (in V), `limsup` and` liminf`; finally the sensor calibration band, `f1` and` f2` in Hz.\n",
    "\n",
    "The A/D system has an approximate sample rate of $ f_m = 256 $ Hz, although the sampling time interval is 3906.000000 $\\mu$s, which is slightly less than $ 1 / f_m $. In one hour, a total of 921600 samples are taken, so the time length of each file is 3599.7696 s, which means a delay of 0.2304 seconds every hour. For this reason, the last file of each month with uninterrupted measurements ends a few minutes sooner than the beginning of the first file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article Rodríguez‐Camacho et al. (2018) presents a study on possible methodologies for the analysis of the station data and their impact on the results obtained, which are the parameters associated to the Schumann resonances. As a final result of the study, a methodology has been established, and the software is presented in this and other notebooks (supplementary material of the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definition of the parameters of the scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of the parameters of the data analysis and the FFT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "divi=6          \n",
    "nleeventa=2560  # 10 s SIGNAL\n",
    "nventa=2**13    # df window\n",
    "nventa2=nventa//2+1\n",
    "df=float(fmues)/float(nventa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 10-min interval is defined with the corresponding value of the fraction of an hour (1 hour/`divi`).\n",
    "\n",
    "Each 10-min interval is divided into 10s long windows, corresponding to `nleeventa = 2560` samples. That is, we work with two intervals: one of 10 s where the FFT is carried out and another of 10-min where the squared spectra of each previous intervals are averaged.\n",
    "\n",
    "The FFT time window is defined with the variable `nventa =`2$^{13}$ = 8192 samples (a little more than 30 s; 30\\*256 = 7680 samples). That is to say, `nleeventa` data samples are extended with zeros to` nventa`.\n",
    "This time window defines the increment in frequencies, $df$, of the obtained spectrum. Considering that $df=1/(N*dt)=f_m/N$, where $f_m$=256 Hz (sampling frequency) and $ N $=`nventa`, results $ df $ = 256/2 $^{13}$ = 1/32 = 0.03125 Hz.\n",
    "\n",
    "The FFT returns `nventa2 = nventa/2+1` real values that constitute the amplitude spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrays to perform the FFT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosventa=np.zeros(nventa,dtype=float)     # For fft\n",
    "datosDF=np.zeros(nventa2,dtype=float)\n",
    "def pofre(f,df,fi):\n",
    "    return int(round((f-fi)/df))\n",
    "listafrec=np.arange(0,nventa2)*fmues/nventa   # frequency list\n",
    "listafreccal=listafrec[pofre(f1,df,0.):pofre(f2,df,0.)+1]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables for the FFT are defined. The array `datosventa` stores the measures and the added zeros, while the transformated data are stored in `datosDF`. The array `listafrec` contains the list of frequencies and the array `listafreccal` the calibrated part of them.\n",
    "The `pofre` function determines the position of a frequency `f` within the frequency array that begins with `fi` and has `df` as frequency increment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Welch method and Hann window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables used in the Welch method and Hann window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhoradivi=nhora//divi  # 10 m interval data number (divi=6)\n",
    "nw=nhoradivi          # Whel's method: number of data\n",
    "mw=nleeventa          # Whel's method: window\n",
    "pw=nleeventa//2       # Whel's method: swapping\n",
    "ninter=int(np.round((nw-mw)/pw+1))  # Number of intervals\n",
    "def hann(m):                          # Hann window\n",
    "    val=np.arange(0,m)\n",
    "    hannv=1.0-np.cos(val*np.pi/m)**2\n",
    "    nor=np.sqrt(np.sum(hannv**2)/m)\n",
    "    return hannv/nor\n",
    "hannvs=hann(mw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the Welch's method, the FFT of a set of `n` (10-min) data, taken in groups of `m` data (10 s) and with a shift of `p` (5 s) data is made. The `m` data window is expanded with zeros to `nventa` samples.\n",
    "\n",
    "The number of intervals generated from `n`, `m` and `p` is $\\left[(n-m)/p \\right] +1$, where `[ ]` is the integer part.  \n",
    "\n",
    "The Hann's window with `m` samples is defined by:  :\n",
    "$$\n",
    "h(i)=1-\\cos^2\\big(\\pi \\cdot (i-1)/m\\big)\n",
    "$$\n",
    "for $i=1,\\dots,m$, with the normalizing factor:\n",
    "$$\n",
    "\\sqrt{\\sum_{i=1}^{m} h(i)^2/m }\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calibration function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibration of the amplitude spectrum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lmag= 298E3\n",
    "Cs= 40E-12\n",
    "Cc= 0.65*55E-12    #35.75E-12\n",
    "Ce= 2E-12\n",
    "Ctot= Cs+Cc+Ce\n",
    "Rmag= 320E3\n",
    "facAmp= 2500.0\n",
    "facSen= 1.9E6\n",
    "f0= 1/(2.0*np.pi*np.sqrt(Ctot*Lmag))\n",
    "delta= Rmag/2.0*np.sqrt(Ctot/Lmag)\n",
    "def Scal(f):\n",
    "    fac1= 1.E12/(facAmp*facSen)\n",
    "    fac2= np.sqrt((1-(f/f0)**2)**2+(2.*delta*f/f0)**2)\n",
    "    fac3= 1/f\n",
    "    return fac1*fac2*fac3\n",
    "funcal= Scal(listafreccal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibrated magnetic field amplitude is given by:\n",
    "\n",
    "$$B (f) = S_c (f) V (f)$$\n",
    "\n",
    "with $f$ in the \\[6 Hz, 25 Hz\\] interval. $B(f)$ is the magnetic field (in T/$\\sqrt{\\text{Hz}}$), $V(f)$ is the Fourier transformed voltage and $S_c(f)$ is the calibration coeficient for each frequency $f$.\n",
    "\n",
    "The function $S_c (f)$ is given by:\n",
    "$$S_c (f) = \\frac{1}{2500}  \\frac{1}{1.9 \\times 10^{6}}  \\frac{1}{f} \n",
    "\\sqrt{\\left( 1 - \\left( \\frac{f}{f_0} \\right)^2 \\right)^2 + \\left( 2 \\delta\n",
    "\\frac{f}{f_0} \\right)^2}$$\n",
    "\n",
    "where $1/2500 $ is the amplification factor, $1/(1.9 \\times 10^6)$ is the magnetometer sensitivity, $1 / f$ is given by Faraday's induction law. $f_0$ and $\\delta$ are the resonance frequency and dumping factor, respectively, of the equivalent RCL of the measurement system and they can be calculated from:\n",
    "\n",
    "$$ f_0=\\frac{1}{2 \\pi \\sqrt{L C_T}}$$\n",
    "\n",
    "$$ \\delta=\\frac{R}{2}\\sqrt{\\frac{C_T}{L}} $$\n",
    "\n",
    "where $R=320$ k$\\Omega$ is the magnetometer resistance, $L=298$ kH is the magnetometer inductance and \n",
    "\n",
    "$$C_T = C_{sensor} + C_{cable} + C_e$$\n",
    "\n",
    "where $C_{sensor} = 40 $ pF is the sensor capacitance,\n",
    "$C_{cable} = (0.65 \\text{ m}) \\times (55 \\times 10^{- 12} \\text{ F/m}) = 35.75$ pF is the wire (that conects the magnetometer to the pre-amplification stage) capacitance evaluated as the product of the length by the capacitance per unit length, $C_e = 2 $ pF is the capacitance of the operational amplifier located in the pre-amplification stage.\n",
    "\n",
    "The factor $10^{12}$ converts the magnetic field units in $\\text{pT}/\\sqrt{\\text{Hz}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading the names of the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data filenames are loaded from the files `ficheros0` and `ficheros1` for sensor NS and EW respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24 hours\n"
     ]
    }
   ],
   "source": [
    "# Reading files with the name of files\n",
    "ficheros0=open(pin+'ficheros0')\n",
    "sensor0=[]\n",
    "for line in ficheros0:\n",
    "    sensor0.append(line[:-1])\n",
    "ficheros1=open(pin+'ficheros1')\n",
    "sensor1=[]\n",
    "for line in ficheros1:\n",
    "    sensor1.append(line[:-1])\n",
    "if (len(sensor0) != len(sensor1)):\n",
    "    print(\"Alert in files\")\n",
    "nhoras=len(sensor0)\n",
    "print(\"Processing {0} hours\".format(nhoras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate the data filenames reading, two files `ficheros0` and` ficheros1` have been generated containing the specific names of the data files for each month and for each sensor. \n",
    "These files are loaded in the previous sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The processing of the measures for the month is done. A loop is made for each sensor, for each hour and for each 10-min interval.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor 0\n",
      "Hour 0\n",
      "It has been found 3 saturations\n",
      "Hour 1\n",
      "It has been found 0 saturations\n",
      "Hour 2\n",
      "It has been found 0 saturations\n",
      "Hour 3\n",
      "It has been found 0 saturations\n",
      "Hour 4\n",
      "It has been found 4 saturations\n",
      "Hour 5\n",
      "It has been found 0 saturations\n",
      "Hour 6\n",
      "It has been found 0 saturations\n",
      "Hour 7\n",
      "It has been found 7 saturations\n",
      "Hour 8\n",
      "It has been found 3 saturations\n",
      "Hour 9\n",
      "It has been found 4 saturations\n",
      "Hour 10\n",
      "It has been found 18 saturations\n",
      "Hour 11\n",
      "It has been found 0 saturations\n",
      "Hour 12\n",
      "It has been found 0 saturations\n",
      "Hour 13\n",
      "It has been found 0 saturations\n",
      "Hour 14\n",
      "It has been found 0 saturations\n",
      "Hour 15\n",
      "It has been found 3 saturations\n",
      "Hour 16\n",
      "It has been found 3 saturations\n",
      "Hour 17\n",
      "It has been found 0 saturations\n",
      "Hour 18\n",
      "It has been found 0 saturations\n",
      "Hour 19\n",
      "It has been found 9 saturations\n",
      "Hour 20\n",
      "It has been found 2 saturations\n",
      "Hour 21\n",
      "It has been found 0 saturations\n",
      "Hour 22\n",
      "It has been found 1 saturations\n",
      "Hour 23\n",
      "It has been found 2 saturations\n",
      "Sensor 1\n",
      "Hour 0\n",
      "It has been found 0 saturations\n",
      "Hour 1\n",
      "It has been found 0 saturations\n",
      "Hour 2\n",
      "It has been found 0 saturations\n",
      "Hour 3\n",
      "It has been found 0 saturations\n",
      "Hour 4\n",
      "It has been found 0 saturations\n",
      "Hour 5\n",
      "It has been found 0 saturations\n",
      "Hour 6\n",
      "It has been found 0 saturations\n",
      "Hour 7\n",
      "It has been found 0 saturations\n",
      "Hour 8\n",
      "It has been found 0 saturations\n",
      "Hour 9\n",
      "It has been found 0 saturations\n",
      "Hour 10\n",
      "It has been found 0 saturations\n",
      "Hour 11\n",
      "It has been found 0 saturations\n",
      "Hour 12\n",
      "It has been found 0 saturations\n",
      "Hour 13\n",
      "It has been found 0 saturations\n",
      "Hour 14\n",
      "It has been found 0 saturations\n",
      "Hour 15\n",
      "It has been found 0 saturations\n",
      "Hour 16\n",
      "It has been found 0 saturations\n",
      "Hour 17\n",
      "It has been found 0 saturations\n",
      "Hour 18\n",
      "It has been found 0 saturations\n",
      "Hour 19\n",
      "It has been found 0 saturations\n",
      "Hour 20\n",
      "It has been found 0 saturations\n",
      "Hour 21\n",
      "It has been found 0 saturations\n",
      "Hour 22\n",
      "It has been found 0 saturations\n",
      "Hour 23\n",
      "It has been found 0 saturations\n"
     ]
    }
   ],
   "source": [
    "# Sensor loop\n",
    "for ise in range(2):\n",
    "    print(\"Sensor {0}\".format(ise))\n",
    "    if (ise == 0):\n",
    "        leesensor=sensor0\n",
    "    else:\n",
    "        leesensor=sensor1\n",
    "# Opening output files\n",
    "    satper=open(pou+'SR'+month+'_satper_'+str(ise),'w')\n",
    "    media=open(pou+'SR'+month+'_media_'+str(ise),'w')\n",
    "\n",
    "    for ihora in range(nhoras):\n",
    "        print(\"Hour {0}\".format(ihora))\n",
    "# Reading hours\n",
    "        hora= np.array(np.fromfile(pin+leesensor[ihora],\\\n",
    "                           dtype='int16'),dtype='float')*facdat      \n",
    "## \n",
    "        nsath=len(hora[(liminf>hora)]) + len(hora[(limsup<hora)])\n",
    "        \n",
    "        print(\"It has been found {0} saturations\".format(nsath))\n",
    "\n",
    "# Each hour is divided in 6 parts\n",
    "        for idivi in range(divi):\n",
    "            horadivi=hora[idivi*nhoradivi:(idivi+1)*nhoradivi]\n",
    "            nsat=0\n",
    "            datosDF[:]=0.\n",
    "# Each 10s\n",
    "            for iinter in range(ninter):\n",
    "                ninf=iinter*pw\n",
    "                nsup=ninf+mw\n",
    "                horainter=horadivi[ninf:nsup]\n",
    "                nsatinter=len(horainter[(liminf>horainter)]) +\\\n",
    "                          len(horainter[(limsup<horainter)])\n",
    "                if (nsatinter==0):\n",
    "                    datosventa[0:mw]=horainter*hannvs\n",
    "                    datosDF += np.abs(np.fft.rfft(datosventa))**2\n",
    "                else:\n",
    "                    nsat += 1\n",
    "# 10 min interval finished\n",
    "            if (nsat == ninter):\n",
    "                print(\"ALERT: ALL INTERVALS ARE SATARATED\")\n",
    "                print('Sensor {0} hour {1}'.format(ise, ihora+1))\n",
    "            else:\n",
    "                datosDF = np.sqrt(datosDF*2./((ninter-nsat)*fmues*mw))\n",
    "                datosDF[0] /= np.sqrt(2.)\n",
    "                datosDF[-1] /= np.sqrt(2.)\n",
    "\n",
    "            datos_Bfield= datosDF[pofre(f1,df,0.):pofre(f2,df,0.)+1]*funcal\n",
    "            print(*datos_Bfield, sep='\\n', file=media)\n",
    "            print(nsat/ninter, file=satper)\n",
    "           \n",
    "# Hours loop finished\n",
    "    satper.close()\n",
    "    media.close()   \n",
    "# Sensors loop finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code that collects all the processing through the following nested loops:\n",
    "1. Sensor loop: 0 and 1\n",
    "2. Loop for each hour of data\n",
    "3. Loop for each 10-min intervals into which each hour is divided\n",
    "4. Loop to process each 10s signal intervals into which each 10-min interval is divided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code **will be broken down**\n",
    "and explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Sensor loop: 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sensor loop: output files are opened: `satper`, `media`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sensors loop\n",
    "for ise in range(2):\n",
    "    print(\"Sensor {0}\".format(ise))\n",
    "    if (ise == 0):\n",
    "        leesensor=sensor0\n",
    "    else:\n",
    "        leesensor=sensor1\n",
    "# Output files\n",
    "    satper=open(pou+'SR'+month+'_satper_'+str(ise),'w')\n",
    "    media=open(pou+'SR'+month+'_media_'+str(ise),'w')\n",
    "\n",
    "    for ihora in range(nhoras): \n",
    "    # ....\n",
    "# Hours loop finished\n",
    "    satper.close()\n",
    "    media.close()\n",
    "# Sensors loop finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output files, for each sensor (0, NS oriented, or 1, EW oriented) are opened: ` satper_0,1` and `media_0,1`. The output path defines the directory for each month. In order to open these files without generating an error in the code, the directories for the output path corresponding to the year and month that are being analyzed must have been created.\n",
    "\n",
    "The sensor loop closes at the end of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6.2 Loop for each hour of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Within the sensor loop, a new one is started for each hour: the data file corresponding to that hour is loaded; its saturations, if any, are detected and shown on the screen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ihora in range(nhoras):\n",
    "        print(\"Hour {0}\".format(ihora))\n",
    "# Reading hours\n",
    "        hora= np.array(np.fromfile(pin+leesensor[ihora],\\\n",
    "                           dtype='int16'),dtype='float')*facdat      \n",
    "## \n",
    "        nsath=len(hora[(liminf>hora)]) + len(hora[(limsup<hora)])\n",
    "        \n",
    "        print(\"{0} saturations have been found\".format(nsath))\n",
    "\n",
    "# Each hour is divided in 6 parts\n",
    "        for idivi in range(divi):\n",
    "            # ...\n",
    "\n",
    "# Hours loop finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hour data loop is started. Data for each hour are read in binary format (integer16) and is multiplied by `facdat` that takes into account the voltage amplitude ($\\pm$10 V) and the 16 bits of the A/D system. \n",
    "In addition, the number of saturations in this hour is determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Loop for 10-min intervals into which each hour is divided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop for each 10-min data interval. The corresponding data inverval is taken. Once the interval has been processed (see below) the amplitude spectrum is obtained and saved in the output file `media`. The interval saturation percentage is stored in the output file `satper`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each hour is divided in 6 parts\n",
    "        for idivi in range(divi):\n",
    "            horadivi=hora[idivi*nhoradivi:(idivi+1)*nhoradivi]\n",
    "            nsat=0\n",
    "            datosDF[:]=0.\n",
    "# Each 10 s\n",
    "            for iinter in range(ninter):\n",
    "                # ...\n",
    "# finishing 10 min interval \n",
    "            if (nsat == ninter):\n",
    "                print(\"ALERT: ALL INTERVALS ARE SATURATED\")\n",
    "                print('Sensor {0} hour {1}'.format(ise, ihora+1))\n",
    "            else:\n",
    "                datosDF = np.sqrt(datosDF*2./((ninter-nsat)*fmues*mw))\n",
    "                datosDF[0] /= np.sqrt(2.)\n",
    "                datosDF[-1] /= np.sqrt(2.)\n",
    "\n",
    "            datos_Bfield= datosDF[pf(f1):pf(f2)+1]*funcal\n",
    "            print(*datos_Bfield, sep='\\n', file=media)\n",
    "            print(nsat/ninter, file=satper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing of each 10-min interval begins.\n",
    "For each interval, the amplitude spectrum is calculated (see below) and saved in the array `datosDF`.\n",
    "The variable `nsat` defines how many 10s intervals are saturated, and therefore eliminated from the average.\n",
    "\n",
    "If the 10-min interval has all its 10s intervals saturated, it is necessary to warn.\n",
    "If not, the sum of the power spectra of each 10s interval is multiplied by 2 to take into account the negative frequencies (except the frequency 0 and the one corresponding to the final sample). The result is divided by the total number of intervals (to make the average) and it is also divided by the factor `fmues * mw` which corresponds to the sampling frequency and the number of effective samples (without the added zeros) used for the FFT. The square root of the final result is calculated in order to have the amplitude spectrum.\n",
    "The spectrum of each 10-min interval is written to the output file with `\\n` as separator.\n",
    "\n",
    "Finally, the saturation percentage of the interval, `satpc=nsat/ninter`, is calculated and written in the output file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the processing, the following files are generated:\n",
    "\n",
    "1. SR1603_satper0,1: for each 10-min interval the ratio between saturated and total windows is written. This file is often used to determine the total number of 10-min intervals for each month.\n",
    "2. SR1603_media_0,1: amplitude spectrum for each 10-min interval.\n",
    "\n",
    "During the analysis process, the index of the hour that is being analyzed is displayed on the screen. In case all the windows are saturated, a message of \"ALERT ALL INTERVALS ARE SATURATED\" is generated on the screen. This message can occur for each 10 min interval into which each hour is divided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Loop to process the 10s signal intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loop for the 10s intervals within each 10-min interval. If the 10s interval does not present saturations: the FFT is done using the Hann window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each 10s\n",
    "            for iinter in range(ninter):\n",
    "                ninf=iinter*pw\n",
    "                nsup=ninf+mw\n",
    "                horainter=horadivi[ninf:nsup]\n",
    "                nsatinter=len(horainter[(liminf>horainter)]) +\\\n",
    "                          len(horainter[(limsup<horainter)])\n",
    "                if (nsatinter==0):\n",
    "                    datosventa[0:mw]=horainter*hannvs\n",
    "                    datosDF += np.abs(np.fft.rfft(datosventa))**2\n",
    "                else:\n",
    "                    nsat += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FFT is performed using the function `np.fft.rfft`.\n",
    "\n",
    "Before doing the transformation we must check that there is no saturated data in the window. \n",
    "If so (there are no saturations):\n",
    "\n",
    "* The data is multiplied by Hann's window and the 0s defined in the `datosventa` array, which has the length of `nventa =`$2^{13}$ samples, are kept.\n",
    "* Numpy's real Fourier transform subroutine is called.\n",
    "* The modulus of the transform is calculated and squared.\n",
    "* These values are added for all the 10s windows to make the average in the 10-min interval.\n",
    "\n",
    "If the 10s interval has any saturated samples, the counter of saturated windows in the 10-min interval is incremented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fornieles-Callejón, J., Salinas, A., Toledo-Redondo, S., Portí, J., Méndez, A., Navarro, E. A., Morente-Molinera, J. A., Soto-Aranaz, C., & Ortega-Cayuela, J. S. (2015). Extremely low frequency band station for natural electromagnetic noise measurement. Radio Science, 50, 191–201\n",
    "\n",
    "Rodríguez‐Camacho, J., Fornieles, J., Carrión, M. C., Portí, J. A., Toledo‐Redondo, S., & Salinas, A. (2018). On the Need of a Unified Methodology for Processing Schumann Resonance Measurements. Journal of Geophysical Research: Atmospheres, 123(23), 13,277-13,290. https://doi.org/10.1029/2018JD029462\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
