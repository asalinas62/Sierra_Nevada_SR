{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V:2021/10/08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program `Reading_Fourier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the data from the Sierra Nevada ELF station is read and the amplitude spectrum is obtained using the Welch method. A 10 s time window is used to do the FFT and the square of the spectrum is averaged over 10 min intervals. The amplitude spectrum is obtained by evaluating the square root of the previous value. 10 s time windows that present saturations (voltage outside the range of the measurement system) are discarded and a saturation index is defined that collects the percentage of such eliminated intervals in each 10-minute interval in which average is performed.\n",
    "\n",
    "As a final result of this step, the 10 min amplitude spectra intervals of measurements in each month is obtained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sierra Nevada ELF station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "year='2015'\n",
    "month='1503'\n",
    "pathin='S_N_Data/'           # Have to be specified      \n",
    "pathout='S_N_DF/'       # for each computer\n",
    "pin=pathin+year+'/'+month+'/'\n",
    "pou=pathout+year+'/'+month+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected at the Sierra Nevada ELF station are grouped by years and within each year by months: `pathin + '/2015/1503'`, where 2015 and 1503 correspond to the year 2015 and the month of March. The figures for the year are repeated in order to avoid writing errors in the processing.\n",
    "The station data are in the directory 'S_N_Data' (indicated by the variable `pathin`) and the outputs of the processing carried out are located in 'S_N_DF' (indicated by the variable` pathout`). The directories for each year and each month must be created.  There are both, the raw data (in 'S_N_Data') and the processed processed data (in 'S_N_DF'), in the data location.\n",
    "\n",
    "Each month has associated data files for each sensor and each hour and in turn each hour has a data file and another one with information on the start time, time increment used and number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the directory for each month there are, in addition, two files, ` ficheros0` and `ficheros1` that contain the name of the file for each hour and for each sensor in order not to need to use system commands to identify the file names.\n",
    "The nomenclature of each file is, for example, `smplGRTU1_sensor_0_1604301629`, where` smplGRTU1_sensor_` is common to all files, then 0 or 1 comes as it corresponds to the sensor with NS orientation or EW orientation, respectively, and then there are pairs of numbers for the year, 16, month, 04, day, 30, hour, 16, and starting minute, 29. The information file has the same name but ends in `_info.txt`. There are some months that are not complete due to problems arisen at the station or due to maintenance work.\n",
    "\n",
    "The A/D system has an approximate sample rate of $ f_m = 256 $ Hz, although the sampling time interval is 3906.000000 $\\mu$s, which is slightly less than $ 1 / f_m $. In one hour, a total of 921600 samples are taken, so the time length of each file is 3599.7696 s, which means a delay of 0.2304 seconds every hour. For this reason, the last file of each month with uninterrupted measurements ends a few minutes sooner than the beginning of the first file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code, the year and month of reading are first identified.\n",
    "The input and output paths are set below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article Rodríguez‐Camacho et al. (2018) presents a study on possible methodologies for the analysis of the station data and their impact on the results obtained, which are the Schumann resonances. As a final result of the study, a methodology has been established and the software of which is presented in this notebook and in the supplementary material of this paper.\n",
    "As a consequence of this process, options appear in the code that are finally fixed. Naturally, these options can be modified but it would imply a systematic monitoring of the outputs of each part of the analysis process, which has been eliminated in the code presented, although some discussion remains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Several values definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "divi=6          # Others options (1,2,3,4)\n",
    "nleeventa=2560  # 10 s SIGNAL\n",
    "nventa=2**13    # df window\n",
    "nventa2=nventa//2+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy package is used and imported with the alias `np`.\n",
    "The 10 min interval, where the amplitude spectrum of the signal is to be averaged, is defined with the corresponding value of the fraction of an hour (1 hour/`divi`). Different intervals have been studied (the value of the variable `divi` could be (1,2,3,4,6). Finally, an interval of 10 m has been chosen (`divi = 6`).\n",
    "\n",
    "Each 10 min interval is divided into 10 s long windows, corresponding to `nleeventa = 2560` samples. That is, we work with two intervals: one of 10 s where the Fast Fourier Transform (FFT) is carried out and another of 10 min where the (squared) spectra of each previous intervals are averaged.\n",
    "\n",
    "In order to do the FFT, the time window is defined with the variable `nventa =`2$^{13}$ = 8192 samples (a little more than 30 s; 30\\*256 = 7680 samples). For this, `nleeventa` data samples are used and it is extended with zeros to` nventa`.\n",
    "This defines the increment in frequencies of the obtained spectrum. Considering that $df=1/(N*dt)=f_m/N$, where $f_m$=256 Hz (sampling frequency) and $ N $=`nventa`, results $ df $ = 256/2 $^{13}$ = 1/32 = 0.03125 Hz.\n",
    "\n",
    "The discrete Fourier transform returns `nventa2 = nventa/2+1` samples that constitute the spectrum in amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general process of the program for each month performs the following steps: \n",
    "- determines the number of files corresponding to the number of hours in that month;\n",
    "- reads the names of all the files and for each one it divides the data according to the variable `divi`;\n",
    "- generates the temporary windows according to the value of the `nleeventa` variable; \n",
    "- determines if the window has saturated values and in that case eliminates them (in that case it leaves the transform at zero and launches a message);\n",
    "- if there are not saturations, adds the number of zeros necessary to make the FFT and returns the transform;\n",
    "- calibration is carried out in the frequency band from 6 to 25 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmues=256       # Hz sampling freq\n",
    "facdat=10.0/2**15   # Sampling factor\n",
    "nhora=fmues*3600  # 921600   # Data per hour\n",
    "df=float(fmues)/float(nventa)\n",
    "limsup=9.990        # Saturation superior bound\n",
    "liminf=-9.990        # Saturation lower bound\n",
    "(f1,f2)=(6,25)   # Calibrated band limits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the parameters of the measurement system: the sampling frequency `fmues`, the sampling factor (corresponds to the maximum voltage value, 10 V, divided by the factor corresponding to 15-bit, 16-bit sampling system minus 1 for the sign), `facdat`; the number of samples in an hour, `nhora`; the upper and lower limits of the measurement (in V) to consider it as saturation, `limsup` and` liminf`; finally the limits of the operating band of the system under calibration conditions, `f1` and` f2` in Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosventa=np.zeros(nventa,dtype=float)     # For fft\n",
    "datosDF=np.zeros(nventa2,dtype=float)\n",
    "def pofre(f,df,fi):\n",
    "    return int(round((f-fi)/df))\n",
    "listafrec=np.arange(0,nventa2)*fmues/nventa   # frequency list\n",
    "listafreccal=listafrec[pofre(f1,df,0.):pofre(f2,df,0.)+1]       # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables for the FFT are defined. The array `datosventa` stores the measures and the added zeros, while the transformated data are stored in `datosDF`. The arrays `listafrec` contains the list of frequencies and `listafreccal` the calibrated part of them.\n",
    "The `pofre` function determines the position of a frequency `f` within the frequency array that begin with `fi` and has `df` as frequency increment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Welch method and Hann window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhoradivi=nhora//divi  # 10 m interval data number (divi=6)\n",
    "nw=nhoradivi          # Whel's method: number of data\n",
    "mw=nleeventa          # Whel's method: window\n",
    "pw=nleeventa//2       # Whel's method: swapping\n",
    "ninter=int(np.round((nw-mw)/pw+1))  # Number of intervals\n",
    "def hann(m):                          # Hann window\n",
    "    val=np.arange(0,m)\n",
    "    hannv=1.0-np.cos(val*np.pi/m)**2\n",
    "    nor=np.sqrt(np.sum(hannv**2)/m)\n",
    "    return hannv/nor\n",
    "hannvs=hann(mw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply Welch's method, the FFT of a set of `n` (10 min) data, taken in groups of `m` data (10 s) and with a shift of `p` data is made. The `m` data window is expanded with zeros to `nventa` samples.\n",
    "\n",
    "The number of intervals generated from `n`, `m` and `p` is $\\left[(n-m)/p \\right] +1$, where `[ ]` is the integer part.  \n",
    "\n",
    "The Hann's window with `m` samples is defined by:  :\n",
    "$$\n",
    "h(i)=1-\\cos^2\\big(\\pi \\cdot (i-1)/m\\big)\n",
    "$$\n",
    "for $i=1,\\dots,m$, with the normalizing factor:\n",
    "$$\n",
    "\\sqrt{\\sum_{i=1}^{m} h(i)^2/m }\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calibration function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lmag= 298E3\n",
    "Cs= 40E-12\n",
    "Cc= 0.65*55E-12    #35.75E-12\n",
    "Ce= 2E-12\n",
    "Ctot= Cs+Cc+Ce\n",
    "Rmag= 320E3\n",
    "facAmp= 2500.0\n",
    "facSen= 1.9E6\n",
    "f0= 1/(2.0*np.pi*np.sqrt(Ctot*Lmag))\n",
    "delta= Rmag/2.0*np.sqrt(Ctot/Lmag)\n",
    "def Scal(f):\n",
    "    fac1= 1.E12/(facAmp*facSen)\n",
    "    fac2= np.sqrt((1-(f/f0)**2)**2+(2.*delta*f/f0)**2)\n",
    "    fac3= 1/f\n",
    "    return fac1*fac2*fac3\n",
    "funcal= Scal(listafreccal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calibrated magnetic field is given by:\n",
    "\n",
    "$$B (f) = S_c (f) V (f)$$\n",
    "\n",
    "with $f$ in the \\[6 Hz, 25 Hz\\] interval. $B(f)$ is the magnetic field (in T/$\\sqrt{\\text{Hz}}$), $V(f)$ is the transformed voltage and $S_c(f)$ is the calibration coeficient for each frequency $f$.\n",
    "\n",
    "The function $S_c (f)$ is given by:\n",
    "$$S_c (f) = \\frac{1}{2500}  \\frac{1}{1.9 \\times 10^{6}}  \\frac{1}{f} \n",
    "\\sqrt{\\left( 1 - \\left( \\frac{f}{f_0} \\right)^2 \\right)^2 + \\left( 2 \\delta\n",
    "\\frac{f}{f_0} \\right)^2}$$\n",
    "\n",
    "where $1/2500 $ is the amplification factor, $1/(1.9 \\times 10^6)$ is the magnetometer sensitivity, $1 / f$ is given by Faraday's induction law. $f_0$ and $\\delta$ are the resonance frequency and dumping factor, respectively, of the equivalent RCL of the measurement system and they can be calculated from:\n",
    "\n",
    "$$ f_0=\\frac{1}{2 \\pi \\sqrt{L C_T}}$$\n",
    "\n",
    "$$ \\delta=\\frac{R}{2}\\sqrt{\\frac{C_T}{L}} $$\n",
    "\n",
    "where $R$ is the magnetometer resistance, $L$ is the magnetometer inductance and \n",
    "\n",
    "$$C_T = C_{sensor} + C_{cable} + C_e$$\n",
    "\n",
    "where $C_{sensor} = 40 $ pF is the sensor capacitance,\n",
    "$C_{cable} = (0.65 \\text{ m}) \\times (55 \\times 10^{- 12} \\text{ F/m}) = 35.75$ pF is the wire (that conects the magnetometer to the pre-amplification stage) capacitance evaluated as the product of the length by the capacitance per unit length, $C_e = 2 $ pF is the capacitance of the operational amplifier located in the pre-amplification stage.\n",
    "\n",
    "The factor $10^{12}$ converts the magnetic field units in $\\text{pT}/\\sqrt{\\text{Hz}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reading the names of the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 24 hours\n"
     ]
    }
   ],
   "source": [
    "# Reading files with the name of files\n",
    "ficheros0=open(pin+'ficheros0')\n",
    "sensor0=[]\n",
    "for line in ficheros0:\n",
    "    sensor0.append(line[:-1])\n",
    "ficheros1=open(pin+'ficheros1')\n",
    "sensor1=[]\n",
    "for line in ficheros1:\n",
    "    sensor1.append(line[:-1])\n",
    "if (len(sensor0) != len(sensor1)):\n",
    "    print(\"Alert in files\")\n",
    "nhoras=len(sensor0)\n",
    "print(\"Processing {0} hours\".format(nhoras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the file names contain the time of their creation, a rule that defines the name a priori cannot be established, but they must be read directly. In order to be able to do it independently of the operating system in which we are working, two files `ficheros0` and` ficheros1` have been generated with the specific names of the data files for each month and for each sensor. These files are read in the previous sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor 0\n",
      "Hour 0\n",
      "It has been found 3 saturations\n",
      "Hour 1\n",
      "It has been found 0 saturations\n",
      "Hour 2\n",
      "It has been found 0 saturations\n",
      "Hour 3\n",
      "It has been found 0 saturations\n",
      "Hour 4\n",
      "It has been found 4 saturations\n",
      "Hour 5\n",
      "It has been found 0 saturations\n",
      "Hour 6\n",
      "It has been found 0 saturations\n",
      "Hour 7\n",
      "It has been found 7 saturations\n",
      "Hour 8\n",
      "It has been found 3 saturations\n",
      "Hour 9\n",
      "It has been found 4 saturations\n",
      "Hour 10\n",
      "It has been found 18 saturations\n",
      "Hour 11\n",
      "It has been found 0 saturations\n",
      "Hour 12\n",
      "It has been found 0 saturations\n",
      "Hour 13\n",
      "It has been found 0 saturations\n",
      "Hour 14\n",
      "It has been found 0 saturations\n",
      "Hour 15\n",
      "It has been found 3 saturations\n",
      "Hour 16\n",
      "It has been found 3 saturations\n",
      "Hour 17\n",
      "It has been found 0 saturations\n",
      "Hour 18\n",
      "It has been found 0 saturations\n",
      "Hour 19\n",
      "It has been found 9 saturations\n",
      "Hour 20\n",
      "It has been found 2 saturations\n",
      "Hour 21\n",
      "It has been found 0 saturations\n",
      "Hour 22\n",
      "It has been found 1 saturations\n",
      "Hour 23\n",
      "It has been found 2 saturations\n",
      "Sensor 1\n",
      "Hour 0\n",
      "It has been found 0 saturations\n",
      "Hour 1\n",
      "It has been found 0 saturations\n",
      "Hour 2\n",
      "It has been found 0 saturations\n",
      "Hour 3\n",
      "It has been found 0 saturations\n",
      "Hour 4\n",
      "It has been found 0 saturations\n",
      "Hour 5\n",
      "It has been found 0 saturations\n",
      "Hour 6\n",
      "It has been found 0 saturations\n",
      "Hour 7\n",
      "It has been found 0 saturations\n",
      "Hour 8\n",
      "It has been found 0 saturations\n",
      "Hour 9\n",
      "It has been found 0 saturations\n",
      "Hour 10\n",
      "It has been found 0 saturations\n",
      "Hour 11\n",
      "It has been found 0 saturations\n",
      "Hour 12\n",
      "It has been found 0 saturations\n",
      "Hour 13\n",
      "It has been found 0 saturations\n",
      "Hour 14\n",
      "It has been found 0 saturations\n",
      "Hour 15\n",
      "It has been found 0 saturations\n",
      "Hour 16\n",
      "It has been found 0 saturations\n",
      "Hour 17\n",
      "It has been found 0 saturations\n",
      "Hour 18\n",
      "It has been found 0 saturations\n",
      "Hour 19\n",
      "It has been found 0 saturations\n",
      "Hour 20\n",
      "It has been found 0 saturations\n",
      "Hour 21\n",
      "It has been found 0 saturations\n",
      "Hour 22\n",
      "It has been found 0 saturations\n",
      "Hour 23\n",
      "It has been found 0 saturations\n"
     ]
    }
   ],
   "source": [
    "# Sensor loop\n",
    "sensorbreak=-1                           # Figures\n",
    "daybreak=-1                              # Figures\n",
    "hourbreak=-1\n",
    "timebreak=(daybreak-1)*24+hourbreak     # Figures\n",
    "for ise in range(2):\n",
    "    print(\"Sensor {0}\".format(ise))\n",
    "    if (ise == 0):\n",
    "        leesensor=sensor0\n",
    "    else:\n",
    "        leesensor=sensor1\n",
    "# Opening output files\n",
    "    saturados=open(pou+'SR'+month+'_saturados_'+str(ise),'w')\n",
    "    satper=open(pou+'SR'+month+'_satper_'+str(ise),'w')\n",
    "    media=open(pou+'SR'+month+'_media_'+str(ise),'w')\n",
    "\n",
    "    countbreak=1\n",
    "    for ihora in range(nhoras):\n",
    "        print(\"Hour {0}\".format(ihora))\n",
    "# Reading hours\n",
    "        hora= np.array(np.fromfile(pin+leesensor[ihora],\\\n",
    "                           dtype='int16'),dtype='float')*facdat      \n",
    "## \n",
    "        nsath=len(hora[(liminf>hora)]) + len(hora[(limsup<hora)])\n",
    "        \n",
    "        print(\"It has been found {0} saturations\".format(nsath))\n",
    "        if (nsath != 0):\n",
    "            print(ihora+1, nsath, file=saturados)   # Contamos hora desde 1\n",
    "            for i,val in enumerate(hora):\n",
    "                if (limsup<val or liminf>val):\n",
    "#                    print(i,val)\n",
    "                    print(i+1, file=saturados)\n",
    "# Each hour is divided in 6 parts\n",
    "        for idivi in range(divi):\n",
    "            horadivi=hora[idivi*nhoradivi:(idivi+1)*nhoradivi]\n",
    "            nsat=0\n",
    "            datosDF[:]=0.\n",
    "# Each 10s\n",
    "            for iinter in range(ninter):\n",
    "                ninf=iinter*pw\n",
    "                nsup=ninf+mw\n",
    "                horainter=horadivi[ninf:nsup]\n",
    "                nsatinter=len(horainter[(liminf>horainter)]) +\\\n",
    "                          len(horainter[(limsup<horainter)])\n",
    "                if (nsatinter==0):\n",
    "                    datosventa[0:mw]=horainter*hannvs\n",
    "                    datosDF += np.abs(np.fft.rfft(datosventa))**2\n",
    "                else:\n",
    "                    nsat += 1\n",
    "# 10 min interval finished\n",
    "            if (nsat == ninter):\n",
    "                print(\"ALERT: ALL INTERVALS ARE SATARATED\")\n",
    "                print('Sensor {0} hour {1}'.format(ise, ihora+1))\n",
    "            else:\n",
    "                datosDF = np.sqrt(datosDF*2./((ninter-nsat)*fmues*mw))\n",
    "                datosDF[0] /= np.sqrt(2.)\n",
    "                datosDF[-1] /= np.sqrt(2.)\n",
    "\n",
    "            datos_Bfield= datosDF[pofre(f1,df,0.):pofre(f2,df,0.)+1]*funcal\n",
    "            print(*datos_Bfield, sep='\\n', file=media)\n",
    "            print(nsat/ninter, file=satper)\n",
    "        countbreak += 1                         # Figures\n",
    "        if(countbreak == timebreak ): break     # Figures            \n",
    "# Hours loop finished\n",
    "    saturados.close()\n",
    "    satper.close()\n",
    "    media.close()\n",
    "    if (ise == sensorbreak):  break             # Figures    \n",
    "# Sensors loop finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code that collects all the processing through the following nested loops:\n",
    "1. Sensor loop: 0 and 1\n",
    "2. Loop for each hour of data\n",
    "3. Loop for each 10 min intervals into which each hour is divided\n",
    "4. Loop to process each 10 s signal intervals into which each 10 min interval is divided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will be broken down below.\n",
    "\n",
    "Warning: do not run the following code because it is cut from the previous one for easy explanation. It is possible to stop the loops by giving different values to the variables indicated with the legend `Figures`. They correspond to: the sensor (0 or 1), day of the month and hour of the day in which you want to stop the process. If we give values out of range the loops do not stop. These statements can be removed to optimize your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Sensor loop: 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sensors loop\n",
    "for ise in range(2):\n",
    "    print(\"Sensor {0}\".format(ise))\n",
    "    if (ise == 0):\n",
    "        leesensor=sensor0\n",
    "    else:\n",
    "        leesensor=sensor1\n",
    "# Output files\n",
    "    saturados=open(pou+'SR'+month+'_saturados_'+str(ise),'w')\n",
    "    satper=open(pou+'SR'+month+'_satper_'+str(ise),'w')\n",
    "    media=open(pou+'SR'+month+'_media_'+str(ise),'w')\n",
    "\n",
    "    for ihora in range(nhoras): \n",
    "    # ....\n",
    "# Hours loop finished\n",
    "    saturados.close()\n",
    "    satper.close()\n",
    "    media.close()\n",
    "# Sensors loop finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the process is done for each sensor, and this loop is closed at the end of the program.\n",
    "\n",
    "The output files, for each sensor (0, NS oriented, or 1, EW oriented) are opened: `saturados_0,1`,` satper_0,1` and `media_0,1` in the output path and in the directory for each month. In order to open these files without generating an error in the code, the directories for the output path corresponding to the year and month that are being analyzed must be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6.2 Loop for each hour of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ihora in range(nhoras):\n",
    "        print(\"Hour {0}\".format(ihora))\n",
    "# Reading hours\n",
    "        hora= np.array(np.fromfile(pin+leesensor[ihora],\\\n",
    "                           dtype='int16'),dtype='float')*facdat      \n",
    "## \n",
    "        nsath=len(hora[(liminf>hora)]) + len(hora[(limsup<hora)])\n",
    "        \n",
    "        print(\"{0} saturations have been found\".format(nsath))\n",
    "        if (nsath != 0):\n",
    "            print(ihora+1, nsath, file=saturados)   # Contamos hora desde 1\n",
    "            for i,val in enumerate(hora):\n",
    "                if (limsup<val or liminf>val):\n",
    "#                    print(i,val)\n",
    "                    print(i+1, file=saturados)\n",
    "# Each hour is divided in 6 parts\n",
    "        for idivi in range(divi):\n",
    "            # ...\n",
    "\n",
    "# Hours loop finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loop that runs through all the hours of the month is then started. Data for each hour are read and it is determined if there are saturations in this hour.\n",
    "If there are, for each one the corresponding index in the file are found and written to the file `saturados`. The numbering of the hours and the indices start the numbering at 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Loop for 10 min intervals into which each hour is divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each hour is divided in 6 parts\n",
    "        for idivi in range(divi):\n",
    "            horadivi=hora[idivi*nhoradivi:(idivi+1)*nhoradivi]\n",
    "            nsat=0\n",
    "            datosDF[:]=0.\n",
    "# Each 10 s\n",
    "            for iinter in range(ninter):\n",
    "                # ...\n",
    "# 10 min interval finished\n",
    "            if (nsat == ninter):\n",
    "                print(\"ALERT: ALL INTERVALS ARE SATURATED\")\n",
    "                print('Sensor {0} hour {1}'.format(ise, ihora+1))\n",
    "            else:\n",
    "                datosDF = np.sqrt(datosDF*2./((ninter-nsat)*fmues*mw))\n",
    "                datosDF[0] /= np.sqrt(2.)\n",
    "                datosDF[-1] /= np.sqrt(2.)\n",
    "\n",
    "            datos_Bfield= datosDF[pf(f1):pf(f2)+1]*funcal\n",
    "            print(*datos_Bfield, sep='\\n', file=media)\n",
    "            print(nsat/ninter, file=satper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now begins the processing of each interval of 10 min.\n",
    "For each interval, its amplitude spectrum must be calculated as the average of the squared spectrum of 10-s intervals of measurements.\n",
    "After reading the data, the array `datosDF` is set to zero.\n",
    "The variable `nsat` defines how many 10 s intervals are saturated, and therefore eliminated from the average.\n",
    "\n",
    "If the 10 min interval (the 10 minutes) has all its 10 s intervals saturated, it is necessary to warn and keep the transformation at zero.\n",
    "If not all the intervals have saturations (`nsat` is different from `ninter`, total number of 10-second intervals with the corresponding overlap) the power spectrum is multiplied by 2 to take into account the negative frequencies (except the frequency 0 and the one corresponding to the final sample). The spectrum is divided by the total number of intervals (to make the average) and it is also divided by the factor `fmues * mw` which corresponds to the sampling frequency and the number of effective samples (without the addition of zeros) used for the FFT. The square root of the final result is calculated in order to have the spectrum in amplitude.\n",
    "The spectrum of each 10 min interval is written to the output file with `\\n` as separator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the saturation percentage of the interval, `satpc=nsat/ninter`, is calculated and written in the output file.\n",
    "\n",
    "As a result of the processing, the following files are generated:\n",
    "\n",
    "1. SR1603_saturados0,1: if in a file (one hour of data) there is saturation, the index of the file (hour) and the number of saturated data are written, and then the index of each data.\n",
    "2. SR1603_satper0,1: for each 10 min interval the quotient between saturated and total windows is written. This file is often used to determine the total number of 10 min intervals for each month.\n",
    "3. SR1603_media_0,1: amplitude spectrum for each 10 min interval.\n",
    "\n",
    "The calibrated frequency limits are 6-25 Hz.\n",
    "\n",
    "During the analysis process, the index of the hour that is being analyzed is displayed on the screen. In case all the windows are saturated, a message of \"ALERT ALL INTERVALS ARE SATURATED\" is generated on the screen. This message can occur for each 10 min interval into which each hour is divided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Loop to process the 10 s signal intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each 10s\n",
    "            for iinter in range(ninter):\n",
    "                ninf=iinter*pw\n",
    "                nsup=ninf+mw\n",
    "                horainter=horadivi[ninf:nsup]\n",
    "                nsatinter=len(horainter[(liminf>horainter)]) +\\\n",
    "                          len(horainter[(limsup<horainter)])\n",
    "                if (nsatinter==0):\n",
    "                    datosventa[0:mw]=horainter*hannvs\n",
    "                    datosDF += np.abs(np.fft.rfft(datosventa))**2\n",
    "                else:\n",
    "                    nsat += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 10 s interval loop the FFT is performed using the function `np.fft.rfft`.\n",
    "\n",
    "Before doing the transformation we must check that there is no saturated data in the window. \n",
    "If so (there are no saturations):\n",
    "\n",
    "* The data is multiplied by Hann's window and the 0s defined in the `datosventa` array, which has the length of `nventa =`$2^{13}$ samples, are kept.\n",
    "* Numpy's real Fourier transform subroutine is called.\n",
    "* The modulus of the transform is calculated and squared.\n",
    "* These values are added for all the windows to make the average in the 10 min interval.\n",
    "\n",
    "If the 10 s interval has any saturated samples, the counter of saturated windows in the interval is incremented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fornieles-Callejón, J., Salinas, A., Toledo-Redondo, S., Portí, J., Méndez, A., Navarro, E. A., Morente-Molinera, J. A., Soto-Aranaz, C., & Ortega-Cayuela, J. S. (2015). Extremely low frequency band station for natural electromagnetic noise measurement. Radio Science, 50, 191–201\n",
    "\n",
    "Rodríguez‐Camacho, J., Fornieles, J., Carrión, M. C., Portí, J. A., Toledo‐Redondo, S., & Salinas, A. (2018). On the Need of a Unified Methodology for Processing Schumann Resonance Measurements. Journal of Geophysical Research: Atmospheres, 123(23), 13,277-13,290. https://doi.org/10.1029/2018JD029462\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
