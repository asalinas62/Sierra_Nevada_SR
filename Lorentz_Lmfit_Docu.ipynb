{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V:2022/04/04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Pseudo code is shown in **bold** in the cell before each piece of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# `Lorentz_Lmfit.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this part of the process is to fit the amplitude spectrum, now free of anthropogenic noise, of each component (NS and EW) of the horizontal magnetic field, for each 10-min interval. Each spectrum, within the calibration band of the magnetometers, is fitted to a sum of three Lorentzian functions and a linear term. The justification of this process, the minimization method and the chosen parameters are explained in Rodríguez‐Camacho (2018). In this section we will focus on explaining the code and how to use the it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process consists of the following steps:\n",
    "1. Loading the amplitude spectrum for each 10-min interval.\n",
    "2. Defining the frequency band, within the calibrated frequency band, in which the Lorentzian fitting is to be performed, \n",
    "3. Choosing the initial parameter values.\n",
    "3. Lorentzian fitting of the amplitude spectrum with the function `lmfit`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lorentzian fit consists on minimizing the mean square error between the experimental spectrum and the function defined by:\n",
    "\n",
    "$$ L(f)=\\sum_{i=1}^{3}\\frac{A_i}{1+\\left( \\frac{f-f_i}{\\sigma_i} \\right)^2}+B f+C $$\n",
    "\n",
    "where $A_i$ stands for the amplitude of the $i$th mode, resonating at frequency $f_i$ and with a bandwidth $\\sigma_i$, while the parameters $B$ and $C$ correspond to the stright line.\n",
    "\n",
    "In addition to these 11 parameters, we can define a global mode amplitude, $ P_i $, as the value of the fitting curve in the resonance frequencies $ f_i $. Namely:\n",
    "\n",
    "$$ P_i=L(f_i) $$\n",
    "\n",
    "which defines a total of 14 parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of this code are, for each sensor:\n",
    "\n",
    "- A list of 14 parameters for each 10-min interval of the month. They correspond to 3 global mode amplitudes, 3 amplitudes, 3 resonance frequencies, 3 resonance frequency widths and 2 parameters of the line (slope and intercept).\n",
    "- A list of the 11 error estimates, each one associated with each parameter for each 10-min interval of the month.\n",
    "- A list of the root mean square error of the fitting in each 10-min interval of the month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a third group of resonance amplitudes and frequencies, local maximum amplitudes and local maximum frequencies, whose calculation is left to the next block code `empaque` in order to separate it from the fitting process itself, which makes it possible to leave it as optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python packages used in the program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lmfit import minimize, Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the packages `numpy`,` lmfit.minimize` and `lmfit.Parameters`. The `lmfit` module is not installed by default within Python. To install it from `pip` we use:\n",
    "\n",
    "`pip install lmfit`\n",
    "\n",
    "If the Python installation was done with Anaconda, we use the instruction:\n",
    "\n",
    "`conda install -c conda-forge lmfit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of paths and station parameters. The initial values for the parameters are also defined.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2015'\n",
    "month='1503'\n",
    "pathg=\"S_N_FD/\"\n",
    "\n",
    "# Station parameters\n",
    "nventa=2**13   # Number of samples in the FFT window\n",
    "fm=256    # Sampling frequency\n",
    "fcal_inf,fcal_sup= 6., 25.         # Calibrated frequency band\n",
    "\n",
    "# Fitting parameters\n",
    "fajus_inf,fajus_sup= 6.35, 23.75   # Fitting frequency band\n",
    "nreso= 3                           # Number of modes\n",
    "# Initial values\n",
    "f1i, f2i, f3i= 8.011, 14.2, 20.63\n",
    "s1i, s2i, s3i= 1.78, 1.94, 2.56\n",
    "mi, ni= 0., 0.\n",
    "metodo= 'leastsq' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of several variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=float(fm)/float(nventa)    # Frequency increment\n",
    "npara= nreso*3+2           # Number of fitting parameters\n",
    "def pofre(f,f0,df):\n",
    "    return int(round((f-f0)/df))\n",
    "fajus_inf_pos= pofre(fajus_inf,fcal_inf,df)\n",
    "fajus_sup_pos= pofre(fajus_sup,fcal_inf,df) \n",
    "fre= np.arange(fcal_inf,fcal_sup+df,df)  \n",
    "nf= len(fre)                                 \n",
    "freajus= fre[fajus_inf_pos : fajus_sup_pos+1]  \n",
    "nfajus= len(freajus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `pofre (f, f0, df)` is defined, which is in charge of finding the position of the frequency `f` within a list that starts with the frequency `f0` and has an increment of `df` (it is considered that the first position is 0).\n",
    "\n",
    "It is convenient to know the position of the first and last frequencies of the\n",
    "fitting band within the list of frequencies in the calibration band, `fajus_inf_pos`and `fajus_sup_pos`. \n",
    "\n",
    "The number of resonances, `nreso = 3`, and the number of fitting parameters,` npara = nreso * 3 + 2` are also defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The 10-min amplitude spectra, free of anthropogenic noise, are loaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "pathmonth=pathg+year+\"/\"+month+\"/\"+\"SR\"+month+\"_\" \n",
    "# Files (output from antropo.py) are loaded\n",
    "rs0= np.genfromtxt(pathmonth+\"mediaNA\"+'_0').reshape(-1,nf)\n",
    "rs0_ajus= rs0[:,fajus_inf_pos : fajus_sup_pos+1]\n",
    "rs1=np.genfromtxt(pathmonth+\"mediaNA\"+'_1').reshape(-1,nf)\n",
    "rs1_ajus= rs1[:,fajus_inf_pos : fajus_sup_pos+1]\n",
    "nintervmes=len(rs0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the previous code, `anthropo`, consisting of the spectra in the calibrated band after removing the anthropogenic noise, is loaded. We do it for each sensor. From these data, we calculate the number of intervals that the month contains, `nintervmes` (it is assumed that for both sensors there is the same number of intervals, so the definition is made for sensor 0).\n",
    "\n",
    "We will work with the spectrum in the calibrated frequency band, `rs0` for sensor NS and `rs1` for sensor EW, and with the part of the spectrum in the fitting frequency band, `rs0_ajus` and `rs1_ajus` respectively. We will therefore have two data lengths, depending on whether we consider spectrum data in the calibrated frequency band or in the adjusted frequency band."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial amplitude values estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The initial amplitude values are defined from the monthly averaged amplitude spectrum.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_ini0= np.array([0.,0.,0.,f1i,f2i,f3i,s1i,s2i,s3i,mi,ni])\n",
    "para_ini1= np.array([0.,0.,0.,f1i,f2i,f3i,s1i,s2i,s3i,mi,ni])\n",
    "f1i_pos= pofre(f1i,fajus_inf,df)\n",
    "f2i_pos= pofre(f2i,fajus_inf,df)\n",
    "f3i_pos= pofre(f3i,fajus_inf,df)\n",
    "\n",
    "rs0_ajus_mediaMes= np.mean(rs0_ajus,0)\n",
    "rs1_ajus_mediaMes= np.mean(rs1_ajus,0)\n",
    "\n",
    "para_ini0[0]= rs0_ajus_mediaMes[f1i_pos] \n",
    "para_ini0[1]= rs0_ajus_mediaMes[f2i_pos] \n",
    "para_ini0[2]= rs0_ajus_mediaMes[f3i_pos]\n",
    "para_ini1[0]= rs1_ajus_mediaMes[f1i_pos] \n",
    "para_ini1[1]= rs1_ajus_mediaMes[f2i_pos] \n",
    "para_ini1[2]= rs1_ajus_mediaMes[f3i_pos]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial values for the amplitude fitting parameters are obtained from the average of the intervals of the month for each sensor (the result of these averages is stored in the arrays `rs0,1_ajus_mediaMes`) at the initial resonance frequency values.\n",
    "\n",
    "The initial parameters of the fitting for the frequencies and the widths are taken from Toledo‐Redondo (2010).  The slope and intercept of the linear part are taken as zero:\n",
    " \n",
    "`f1i, f2i, f3i= 8.011, 14.2, 20.63\n",
    " s1i, s2i, s3i= 1.78, 1.94, 2.56\n",
    " mi, ni= 0., 0.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function `residual` defines the model and data difference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(params, x, data):\n",
    "    v= params.valuesdict()     \n",
    "    model = v['a1']/(1+((x-v['f1'])**2)/v['s1']**2)+\\\n",
    "                v['a2']/(1+((x-v['f2'])**2)/v['s2']**2)+\\\n",
    "                v['a3']/(1+((x-v['f3'])**2)/v['s3']**2)+v['m']*x+v['n']      \n",
    "    return (data-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Parameters()` is used to define the `params` object that we will use in the program. This object has the structure of a dictionary.\n",
    "\n",
    "The function `residual` defines the values to be minimized, which in our case will be defined by Lorentzian functions and a linear term.\n",
    "The arguments are: the dictionary `params`, the frequency list `x`, and the values `data`. \n",
    "Firstly, the values for each parameter of the fitting function are stored in the list `v` through the `.valuesdict ()` method. The Lorentzian function is calculated for each value of the array `x` that must contain all the frequencies of the spectrum of the fitting band. Finally, the list with the difference between the fitting function and the measure is returned by the function and will be minimized with the function `lmfit` that will be called later.\n",
    "\n",
    "This procedure is similar to that presented in the Lmfit package documentation: [Lmfit example](https://lmfit.github.io/lmfit-py/examples/example_fit_with_inequality.html#sphx-glr-examples-example-fit-with-inequality-py). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function `defpar`: Fitting parameters definition. `leepar`, `leeerr`, `leechi`: Output arrays reading.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defpar(params,val):\n",
    "    params.add('a1', value = val[0])\n",
    "    params.add('a2', value = val[1])\n",
    "    params.add('a3', value = val[2])    \n",
    "    params.add('f1', value = val[3])\n",
    "    params.add('f2', value = val[4])\n",
    "    params.add('f3', value = val[5])    \n",
    "    params.add('s1', value= val[6])\n",
    "    params.add('s2', value= val[7])\n",
    "    params.add('s3', value= val[8])    \n",
    "    params.add('m', value= val[9])\n",
    "    params.add('n', value= val[10])\n",
    "# Output reading functions\n",
    "def leepar(salida):\n",
    "    val= np.zeros(11)\n",
    "    val[0]=salida.params['a1'].value\n",
    "    val[1]=salida.params['a2'].value\n",
    "    val[2]=salida.params['a3'].value\n",
    "    val[3]=salida.params['f1'].value\n",
    "    val[4]=salida.params['f2'].value\n",
    "    val[5]=salida.params['f3'].value    \n",
    "    val[6]=salida.params['s1'].value\n",
    "    val[7]=salida.params['s2'].value\n",
    "    val[8]=salida.params['s3'].value\n",
    "    val[9]=salida.params['m'].value\n",
    "    val[10]=salida.params['n'].value\n",
    "    return val\n",
    "    \n",
    "def leeerr(salida):\n",
    "    val= np.zeros(11)\n",
    "    val[0]=salida.params['a1'].stderr\n",
    "    val[1]=salida.params['a2'].stderr\n",
    "    val[2]=salida.params['a3'].stderr\n",
    "    val[3]=salida.params['f1'].stderr\n",
    "    val[4]=salida.params['f2'].stderr\n",
    "    val[5]=salida.params['f3'].stderr   \n",
    "    val[6]=salida.params['s1'].stderr\n",
    "    val[7]=salida.params['s2'].stderr\n",
    "    val[8]=salida.params['s3'].stderr\n",
    "    val[9]=salida.params['m'].stderr\n",
    "    val[10]=salida.params['n'].stderr\n",
    "    return val\n",
    "    \n",
    "def leechi(salida):\n",
    "    return salida.chisqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines fitting functions used together with the `lmfit` function.\n",
    "The `defpar` function defines the dictionary `params` with the keys of each fitting parameter and the values `val`.\n",
    "\n",
    "The function `leepar` extracts the values of the dictionary `params` calculated in the minimization process. The reading of the output for the error in each parameter, function `leeerr`, and the value of the funcion Chi-square,` leechi`, are also performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lorentzian fitting for each 10-min interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition of the output arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params0 = Parameters()\n",
    "params1 = Parameters()\n",
    "defpar(params0, para_ini0)\n",
    "defpar(params1, para_ini1)\n",
    "\n",
    "para_s0= np.zeros((nintervmes, npara),dtype=float)\n",
    "para_s1= np.zeros((nintervmes, npara),dtype=float)\n",
    "salerr0=np.zeros((nintervmes, npara),dtype=float)\n",
    "salerr1=np.zeros((nintervmes, npara),dtype=float)\n",
    "salchi0=np.zeros((nintervmes),dtype=float)\n",
    "salchi1=np.zeros((nintervmes),dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to the definition of the initial parameter values and the initialization of the arrays where the results will be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function `minimize` de `lmfit` is called for each sensor and each 10-min interval. The outputs are saved.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(nintervmes):    \n",
    "    # Sensor 0 \n",
    "    out_s0 = minimize(residual, params0,\\\n",
    "            args=(freajus, rs0_ajus[i]), method = metodo)\n",
    "    para_s0[i]= leepar(out_s0)\n",
    "    salerr0[i]= leeerr(out_s0)\n",
    "    salchi0[i]= leechi(out_s0)\n",
    "    # Sensor 1    \n",
    "    out_s1 = minimize(residual, params1,\\\n",
    "            args=(freajus, rs1_ajus[i]), method = metodo)\n",
    "    para_s1[i]= leepar(out_s1)\n",
    "    salerr1[i]= leeerr(out_s1)\n",
    "    salchi1[i]= leechi(out_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `minimize` function is called and the corresponding outputs are read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global mode amplitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The sum of three lorentzian functions and the linear term is evaluated in each resonant frequency. These are the global mode amplitudes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida0=np.zeros((nintervmes, npara+nreso),dtype=float)\n",
    "salida1=np.zeros((nintervmes, npara+nreso),dtype=float)\n",
    "salida0[:,nreso:]=para_s0[:,:]\n",
    "salida1[:,nreso:]=para_s1[:,:]\n",
    "# Global mode amplitudes are calculated from the global function\n",
    "for i in np.arange(nintervmes):\n",
    "    ampm0 = np.zeros(nreso)\n",
    "    ampm1 = np.zeros(nreso)\n",
    "    for k in np.arange(nreso):\n",
    "        ampm0[k]=para_s0[i,nreso*3]*para_s0[i,nreso+k]+para_s0[i,nreso*3+1]\n",
    "        ampm1[k]=para_s1[i,nreso*3]*para_s1[i,nreso+k]+para_s1[i,nreso*3+1]\n",
    "        for l in np.arange(nreso):\n",
    "            ampm0[k]+= para_s0[i,l]/(1+((para_s0[i,nreso+k]-\\\n",
    "                     para_s0[i,l+nreso])**2)/para_s0[i,l+2*nreso]**2)               \n",
    "            ampm1[k]+= para_s1[i,l]/(1+((para_s1[i,nreso+k]-\\\n",
    "                     para_s1[i,l+nreso])**2)/para_s1[i,l+2*nreso]**2)   \n",
    "    salida0[i,:nreso]=ampm0[:]\n",
    "    salida1[i,:nreso]=ampm1[:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **global mode amplitudes** are the amplitudes corresponding to the values of the sum of the three Lorentzian functions plus the linear term, at each resonance frequency.\n",
    "\n",
    "The global mode amplitudes are calculated for each 10-min interval of the month. The values of the three resonances and the linear terms are saved in the arrays `ampm0, ampm1`.\n",
    "\n",
    "To save these values we define a new array for each sensor with three additional columns that we place at the beginning of the array. In these arrays, `salida0, salida1`, for sensor NS and EW, respectively, the parameters already calculated are stored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output file paths are defined and the output arrays are written**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = pathmonth+\"mediaLO\"+'_0'\n",
    "path1 = pathmonth+\"mediaLO\"+'_1'\n",
    "pathe0 = pathmonth+\"mediaLOE\"+'_0'\n",
    "pathe1 = pathmonth+\"mediaLOE\"+'_1'\n",
    "pathc0 = pathmonth+\"mediaLOC\"+'_0'\n",
    "pathc1 = pathmonth+\"mediaLOC\"+'_1'\n",
    "\n",
    "np.savetxt(path0,salida0.ravel())\n",
    "np.savetxt(path1,salida1.ravel())\n",
    "np.savetxt(pathe0,salerr0.ravel())\n",
    "np.savetxt(pathe1,salerr1.ravel())            \n",
    "np.savetxt(pathc0,salchi0.ravel())\n",
    "np.savetxt(pathc1,salchi1.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we proceed to define the output paths and file names and to write the parameters and errors in one column (for this, we use the `.ravel ()` method).\n",
    "\n",
    "The output files therefore contain: the 14 fitting parameters for each 10-min interval (`mediaLO`), the error generated by the optimization algorithm for each parameter (`mediaLOE`) and the value of the chi-square function for the fitting curve with respect to the measured spectrum, also generated by the optimization algorithm (`mediaLOC`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rodríguez‐Camacho, J., Fornieles, J., Carrión, M. C., Portí, J. A., Toledo‐Redondo, S., & Salinas, A. (2018). On the Need of a Unified Methodology for Processing Schumann Resonance Measurements. Journal of Geophysical Research: Atmospheres, 123(23), 13,277-13,290. https://doi.org/10.1029/2018JD029462\n",
    "\n",
    "Toledo‐Redondo, S., A. Salinas, J. Portí, J. A. Morente, J. Fornieles, A. Méndez, J. Galindo‐Zaldívar, A. Pedrera, A. Ruiz‐Constán, and F. Anahnah (2010), Study of Schumann resonances based on magnetotelluric records from the western Mediterranean and Antarctica, J. Geophys. Res., 115, D22114, doi:10.1029/2010JD014316)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
